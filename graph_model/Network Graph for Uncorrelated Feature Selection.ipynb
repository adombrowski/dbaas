{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to generate independent feature sets using Network Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "One of the core assumptions underpinning many statistical models is independence among the explanatory variables. So let's assume that you want to train your models with variables that are no more than .1 correlated with any other variable in the set. Sounds easy, no?\n",
    "\n",
    "Not quite. You could manually select your variable combinations but that gets taxing quite quickly and only works when you have a low variable count. But let's say you have a modest count of 8 variables. If you choose 2 variables from 8, that's 56 unique pairings. That's simple enough: just look at a corrlation matrix and choose only the pairs below our .1 threshold.\n",
    "\n",
    "But what about groups of 3? That's 336 unique combinations (8 chooses 3 i.e. 8!/(3!(8-3)!)). Furthermore, correlation matrices are pairwise so not only do you need to find the pairs that are uncorrelated, but you need to make sure that no variable is more than .1 correlated with any of the other variables. For instance, if you have variables 1, 2, and 3 you'd need to manually check that (1,2), (1,3), and (2,3) all have correlations below .1\n",
    "\n",
    "And that's just for a feature set of 3! Doing this for 4 is way more taxing (1680 combos), 5 (6720 combos), 6 (2160 combos) and so on.\n",
    "\n",
    "Most data scientists are working with feature sets much larger than the 8 I describe above. \n",
    "\n",
    "##### How can we train multiple models on feature sets of varying size and ensure that none of the feature sets violate our independence assumption?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Inflation Factor\n",
    "\n",
    "A common way to check for the occurence of multicollinearity in a regression model (variable count > 2) is by calculating what's called the Variance Inflation Factor. VIF \"is calculated by taking the the ratio of the variance of all a given model's betas divide by the variance of a single beta if it were fit alone.\" [reference_here](https://etav.github.io/python/vif_factor_python.html). Simply put: VIF attempts to capture how well the rest of a model's variables explain the independent variable you isolated.\n",
    "\n",
    "Variance Inflation Factor calculations are important because they capture multi-collinearity even among variable sets that see low pairwise correlations. So in no way am I suggesting that the method I discuss below is superior/intended to replace it.\n",
    "\n",
    "### Filtering Large Feature Sets\n",
    "\n",
    "But let's assume we have 100 features and we want to experiment with different stacking strategies. In one strategy, we pool a large number of weakly trained ensemble/logit models trained on only a fraction of the feature space. In another strategy, we train a few models on a larger feature set. For both strategies we use the base model outputs as inputs to our higher level model. And also assume that we want to test the efficacy of a one-model approach.\n",
    "\n",
    "If we have 100 features we are left with a very large number of feature combinations that we'll want our script to run through. Furthermore, running VIF analysis on dozens of variables for hundreds if not thousands of models is pretty costly. So how can we filter down the feature space to something more manageable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Challenge\n",
    "\n",
    "I suggested at the beginning that we consider each feature set of varying sizes where all variables contained within the set are no more correlated with any other variable within the set than a stipulated threshold. For simplicity let's just say that the threshold is a correlation of .1\n",
    "\n",
    "Each set then will be comprised of these variables. So let's assume that we have three uncorrelated features: A, B, C. This means:\n",
    "\n",
    "- (A,B), (A,C) and (B,C) all have a correlation < .1\n",
    "\n",
    "So in this case we can train our model on these three pairwise combinations and we can also train on all three variables.\n",
    "\n",
    "Similarly, we see that a set of size 4 can be decomposed into sets of size 3 and 2. Consider A, B, C, D:\n",
    "\n",
    "- (A, B, C), (A, B, D), (A, C, D), (B, C, D) acceptable triangles\n",
    "- (A,B), (A,C), (A,D), (B,C), (B,D), (C,D) acceptable pairwise\n",
    "\n",
    "And so on.\n",
    "\n",
    "We need some way to identify all acceptable groups of varying size. For instance, when testing our strategy of training and stacking many low-dimensional models, we'll need feature sets of size 1-6. However, for training higher dimensional models we'll need to identify feature sets much larger (if they exist)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Graphs\n",
    "\n",
    "I'll close this exposition by discussing how I go about doing this and then I'll provide a walkthrough of my code. Our challenge is three-fold:\n",
    "\n",
    "1. We need to identify all lower-level feature set combinations (the decompositions of a larger set)\n",
    "2. We need to traverse a very large feature space\n",
    "3. We need to do this quickly\n",
    "\n",
    "My theory is that you can treat each set of uncorrelated variables as a complete network, meaning that each node is connected to every other node in the subnetwork. My strategy then is as follows:\n",
    "\n",
    "- Identify all pairs in a correlation matrix that do no exceed our threshold\n",
    "- Convert these pairwise points into a network dictionary\n",
    "- Mine the network for all instances of complete subnetworks of any size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Code\n",
    "\n",
    "I'm going to start by loading two data sets: one containing 25 features, the other containing 127. Both are engineered versions of the Kaggle titanic dataset and have already been normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_df = pd.read_csv(\"data/train_norm.csv\", sep=\",\")\n",
    "large_df = pd.read_csv(\"data/train_norm_large.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove \"Survived\"\n",
    "small_df = small_df.drop(\"Survived\", axis=1)\n",
    "large_df = large_df.drop(\"Survived\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in small feature set: 25\n",
      "Number of features in large feature set: 127\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features in small feature set: {}\".format(len(small_df.columns)))\n",
    "print(\"Number of features in large feature set: {}\".format(len(large_df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting our correlations\n",
    "\n",
    "Let's get a view of our correlation matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.094706</td>\n",
       "      <td>-0.103837</td>\n",
       "      <td>-0.246762</td>\n",
       "      <td>0.124148</td>\n",
       "      <td>0.095006</td>\n",
       "      <td>-0.210181</td>\n",
       "      <td>0.007803</td>\n",
       "      <td>0.067836</td>\n",
       "      <td>-0.079175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134012</td>\n",
       "      <td>-0.268843</td>\n",
       "      <td>0.116998</td>\n",
       "      <td>0.014372</td>\n",
       "      <td>0.081493</td>\n",
       "      <td>0.126311</td>\n",
       "      <td>0.037751</td>\n",
       "      <td>0.069139</td>\n",
       "      <td>-0.335746</td>\n",
       "      <td>0.036142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.094706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.091723</td>\n",
       "      <td>-0.101397</td>\n",
       "      <td>0.031540</td>\n",
       "      <td>0.047170</td>\n",
       "      <td>-0.070402</td>\n",
       "      <td>0.057869</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>-0.057067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169757</td>\n",
       "      <td>-0.100738</td>\n",
       "      <td>-0.081106</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.022539</td>\n",
       "      <td>0.034859</td>\n",
       "      <td>0.016682</td>\n",
       "      <td>0.028670</td>\n",
       "      <td>-0.076085</td>\n",
       "      <td>-0.035789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.103837</td>\n",
       "      <td>-0.091723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.123364</td>\n",
       "      <td>0.097580</td>\n",
       "      <td>0.084204</td>\n",
       "      <td>-0.176511</td>\n",
       "      <td>0.086845</td>\n",
       "      <td>-0.040976</td>\n",
       "      <td>-0.077763</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000541</td>\n",
       "      <td>0.049242</td>\n",
       "      <td>0.118489</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>-0.107925</td>\n",
       "      <td>0.105966</td>\n",
       "      <td>0.034776</td>\n",
       "      <td>0.047261</td>\n",
       "      <td>-0.039550</td>\n",
       "      <td>-0.155727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.246762</td>\n",
       "      <td>-0.101397</td>\n",
       "      <td>-0.123364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.143544</td>\n",
       "      <td>-0.112363</td>\n",
       "      <td>0.108507</td>\n",
       "      <td>-0.136621</td>\n",
       "      <td>-0.136907</td>\n",
       "      <td>0.088725</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.707618</td>\n",
       "      <td>0.857738</td>\n",
       "      <td>-0.581027</td>\n",
       "      <td>-0.070150</td>\n",
       "      <td>-0.046340</td>\n",
       "      <td>-0.129952</td>\n",
       "      <td>-0.055360</td>\n",
       "      <td>-0.109063</td>\n",
       "      <td>0.049980</td>\n",
       "      <td>-0.020764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.124148</td>\n",
       "      <td>0.031540</td>\n",
       "      <td>0.097580</td>\n",
       "      <td>-0.143544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.288145</td>\n",
       "      <td>-0.621220</td>\n",
       "      <td>0.307655</td>\n",
       "      <td>-0.149344</td>\n",
       "      <td>-0.171537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041842</td>\n",
       "      <td>-0.137774</td>\n",
       "      <td>0.110023</td>\n",
       "      <td>0.176303</td>\n",
       "      <td>-0.241679</td>\n",
       "      <td>0.459163</td>\n",
       "      <td>0.524565</td>\n",
       "      <td>-0.185458</td>\n",
       "      <td>-0.356497</td>\n",
       "      <td>-0.126442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.095006</td>\n",
       "      <td>0.047170</td>\n",
       "      <td>0.084204</td>\n",
       "      <td>-0.112363</td>\n",
       "      <td>-0.288145</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.560901</td>\n",
       "      <td>-0.124442</td>\n",
       "      <td>-0.122618</td>\n",
       "      <td>0.190507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007017</td>\n",
       "      <td>-0.131846</td>\n",
       "      <td>0.142598</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>-0.074078</td>\n",
       "      <td>0.124750</td>\n",
       "      <td>-0.153057</td>\n",
       "      <td>0.639519</td>\n",
       "      <td>-0.321464</td>\n",
       "      <td>-0.115498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.210181</td>\n",
       "      <td>-0.070402</td>\n",
       "      <td>-0.176511</td>\n",
       "      <td>0.108507</td>\n",
       "      <td>-0.621220</td>\n",
       "      <td>-0.560901</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.152124</td>\n",
       "      <td>0.243459</td>\n",
       "      <td>-0.007930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037656</td>\n",
       "      <td>0.130900</td>\n",
       "      <td>-0.145158</td>\n",
       "      <td>-0.187849</td>\n",
       "      <td>0.273336</td>\n",
       "      <td>-0.493703</td>\n",
       "      <td>-0.324302</td>\n",
       "      <td>-0.352973</td>\n",
       "      <td>0.587471</td>\n",
       "      <td>0.211628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.007803</td>\n",
       "      <td>0.057869</td>\n",
       "      <td>0.086845</td>\n",
       "      <td>-0.136621</td>\n",
       "      <td>0.307655</td>\n",
       "      <td>-0.124442</td>\n",
       "      <td>-0.152124</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.138898</td>\n",
       "      <td>-0.781418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064391</td>\n",
       "      <td>-0.119726</td>\n",
       "      <td>0.094321</td>\n",
       "      <td>0.071444</td>\n",
       "      <td>0.288894</td>\n",
       "      <td>0.174953</td>\n",
       "      <td>-0.004069</td>\n",
       "      <td>-0.135887</td>\n",
       "      <td>-0.257858</td>\n",
       "      <td>-0.102986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.067836</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>-0.040976</td>\n",
       "      <td>-0.136907</td>\n",
       "      <td>-0.149344</td>\n",
       "      <td>-0.122618</td>\n",
       "      <td>0.243459</td>\n",
       "      <td>-0.138898</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.492727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213648</td>\n",
       "      <td>-0.134138</td>\n",
       "      <td>-0.045748</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>-0.137222</td>\n",
       "      <td>-0.061058</td>\n",
       "      <td>-0.085933</td>\n",
       "      <td>-0.054312</td>\n",
       "      <td>0.327503</td>\n",
       "      <td>-0.059930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.079175</td>\n",
       "      <td>-0.057067</td>\n",
       "      <td>-0.077763</td>\n",
       "      <td>0.088725</td>\n",
       "      <td>-0.171537</td>\n",
       "      <td>0.190507</td>\n",
       "      <td>-0.007930</td>\n",
       "      <td>-0.781418</td>\n",
       "      <td>-0.492727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103434</td>\n",
       "      <td>0.084951</td>\n",
       "      <td>0.018451</td>\n",
       "      <td>-0.055445</td>\n",
       "      <td>-0.161972</td>\n",
       "      <td>-0.113074</td>\n",
       "      <td>0.060780</td>\n",
       "      <td>0.161509</td>\n",
       "      <td>0.042654</td>\n",
       "      <td>0.138988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.016567</td>\n",
       "      <td>0.005920</td>\n",
       "      <td>0.005411</td>\n",
       "      <td>-0.097190</td>\n",
       "      <td>-0.097063</td>\n",
       "      <td>0.217142</td>\n",
       "      <td>-0.081501</td>\n",
       "      <td>-0.076486</td>\n",
       "      <td>-0.041959</td>\n",
       "      <td>0.106560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035120</td>\n",
       "      <td>-0.116055</td>\n",
       "      <td>0.100936</td>\n",
       "      <td>-0.028423</td>\n",
       "      <td>0.012926</td>\n",
       "      <td>0.198164</td>\n",
       "      <td>-0.053122</td>\n",
       "      <td>-0.054912</td>\n",
       "      <td>-0.095879</td>\n",
       "      <td>-0.035264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.153911</td>\n",
       "      <td>-0.024921</td>\n",
       "      <td>0.064228</td>\n",
       "      <td>-0.062808</td>\n",
       "      <td>-0.049614</td>\n",
       "      <td>-0.060501</td>\n",
       "      <td>0.107827</td>\n",
       "      <td>-0.108040</td>\n",
       "      <td>0.179770</td>\n",
       "      <td>-0.000495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059676</td>\n",
       "      <td>-0.064140</td>\n",
       "      <td>0.041467</td>\n",
       "      <td>-0.004874</td>\n",
       "      <td>-0.185460</td>\n",
       "      <td>-0.297672</td>\n",
       "      <td>0.179096</td>\n",
       "      <td>0.191069</td>\n",
       "      <td>0.345046</td>\n",
       "      <td>-0.188285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.121716</td>\n",
       "      <td>0.016302</td>\n",
       "      <td>-0.101414</td>\n",
       "      <td>-0.015729</td>\n",
       "      <td>0.103068</td>\n",
       "      <td>-0.018884</td>\n",
       "      <td>-0.074751</td>\n",
       "      <td>0.163624</td>\n",
       "      <td>-0.151685</td>\n",
       "      <td>-0.049990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015281</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>-0.011810</td>\n",
       "      <td>0.027831</td>\n",
       "      <td>0.180839</td>\n",
       "      <td>0.240122</td>\n",
       "      <td>-0.162093</td>\n",
       "      <td>-0.168888</td>\n",
       "      <td>-0.295760</td>\n",
       "      <td>0.226407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.054265</td>\n",
       "      <td>-0.003001</td>\n",
       "      <td>-0.051775</td>\n",
       "      <td>-0.318921</td>\n",
       "      <td>-0.016694</td>\n",
       "      <td>-0.018851</td>\n",
       "      <td>0.077981</td>\n",
       "      <td>0.005478</td>\n",
       "      <td>0.026527</td>\n",
       "      <td>0.032310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229423</td>\n",
       "      <td>-0.279189</td>\n",
       "      <td>0.204226</td>\n",
       "      <td>0.014780</td>\n",
       "      <td>0.123599</td>\n",
       "      <td>-0.026110</td>\n",
       "      <td>-0.007617</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.019750</td>\n",
       "      <td>0.014271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.031144</td>\n",
       "      <td>0.010618</td>\n",
       "      <td>-0.416147</td>\n",
       "      <td>0.078838</td>\n",
       "      <td>-0.082900</td>\n",
       "      <td>0.009872</td>\n",
       "      <td>0.071362</td>\n",
       "      <td>-0.029355</td>\n",
       "      <td>0.019558</td>\n",
       "      <td>0.022548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044983</td>\n",
       "      <td>-0.340946</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>-0.037224</td>\n",
       "      <td>0.042721</td>\n",
       "      <td>-0.061319</td>\n",
       "      <td>-0.025924</td>\n",
       "      <td>0.021140</td>\n",
       "      <td>0.028129</td>\n",
       "      <td>0.028611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.134012</td>\n",
       "      <td>0.169757</td>\n",
       "      <td>-0.000541</td>\n",
       "      <td>-0.707618</td>\n",
       "      <td>0.041842</td>\n",
       "      <td>0.007017</td>\n",
       "      <td>0.037656</td>\n",
       "      <td>0.064391</td>\n",
       "      <td>0.213648</td>\n",
       "      <td>-0.103434</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.609172</td>\n",
       "      <td>-0.132901</td>\n",
       "      <td>-0.013258</td>\n",
       "      <td>0.043342</td>\n",
       "      <td>0.044507</td>\n",
       "      <td>0.018460</td>\n",
       "      <td>0.034153</td>\n",
       "      <td>0.041790</td>\n",
       "      <td>0.034473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.268843</td>\n",
       "      <td>-0.100738</td>\n",
       "      <td>0.049242</td>\n",
       "      <td>0.857738</td>\n",
       "      <td>-0.137774</td>\n",
       "      <td>-0.131846</td>\n",
       "      <td>0.130900</td>\n",
       "      <td>-0.119726</td>\n",
       "      <td>-0.134138</td>\n",
       "      <td>0.084951</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.609172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.500687</td>\n",
       "      <td>-0.309469</td>\n",
       "      <td>-0.047413</td>\n",
       "      <td>-0.108822</td>\n",
       "      <td>-0.058603</td>\n",
       "      <td>-0.140719</td>\n",
       "      <td>0.075013</td>\n",
       "      <td>-0.014563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.116998</td>\n",
       "      <td>-0.081106</td>\n",
       "      <td>0.118489</td>\n",
       "      <td>-0.581027</td>\n",
       "      <td>0.110023</td>\n",
       "      <td>0.142598</td>\n",
       "      <td>-0.145158</td>\n",
       "      <td>0.094321</td>\n",
       "      <td>-0.045748</td>\n",
       "      <td>0.018451</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132901</td>\n",
       "      <td>-0.500687</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010088</td>\n",
       "      <td>0.026504</td>\n",
       "      <td>0.096022</td>\n",
       "      <td>0.046503</td>\n",
       "      <td>0.104816</td>\n",
       "      <td>-0.071819</td>\n",
       "      <td>0.002208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.014372</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>-0.070150</td>\n",
       "      <td>0.176303</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>-0.187849</td>\n",
       "      <td>0.071444</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>-0.055445</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013258</td>\n",
       "      <td>-0.309469</td>\n",
       "      <td>-0.010088</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.053804</td>\n",
       "      <td>0.080382</td>\n",
       "      <td>0.065121</td>\n",
       "      <td>0.096654</td>\n",
       "      <td>-0.097313</td>\n",
       "      <td>-0.037785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.081493</td>\n",
       "      <td>0.022539</td>\n",
       "      <td>-0.107925</td>\n",
       "      <td>-0.046340</td>\n",
       "      <td>-0.241679</td>\n",
       "      <td>-0.074078</td>\n",
       "      <td>0.273336</td>\n",
       "      <td>0.288894</td>\n",
       "      <td>-0.137222</td>\n",
       "      <td>-0.161972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043342</td>\n",
       "      <td>-0.047413</td>\n",
       "      <td>0.026504</td>\n",
       "      <td>-0.053804</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308082</td>\n",
       "      <td>-0.148254</td>\n",
       "      <td>-0.163339</td>\n",
       "      <td>-0.313380</td>\n",
       "      <td>-0.111046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.126311</td>\n",
       "      <td>0.034859</td>\n",
       "      <td>0.105966</td>\n",
       "      <td>-0.129952</td>\n",
       "      <td>0.459163</td>\n",
       "      <td>0.124750</td>\n",
       "      <td>-0.493703</td>\n",
       "      <td>0.174953</td>\n",
       "      <td>-0.061058</td>\n",
       "      <td>-0.113074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044507</td>\n",
       "      <td>-0.108822</td>\n",
       "      <td>0.096022</td>\n",
       "      <td>0.080382</td>\n",
       "      <td>-0.308082</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.184977</td>\n",
       "      <td>-0.204107</td>\n",
       "      <td>-0.391308</td>\n",
       "      <td>-0.140179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.037751</td>\n",
       "      <td>0.016682</td>\n",
       "      <td>0.034776</td>\n",
       "      <td>-0.055360</td>\n",
       "      <td>0.524565</td>\n",
       "      <td>-0.153057</td>\n",
       "      <td>-0.324302</td>\n",
       "      <td>-0.004069</td>\n",
       "      <td>-0.085933</td>\n",
       "      <td>0.060780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018460</td>\n",
       "      <td>-0.058603</td>\n",
       "      <td>0.046503</td>\n",
       "      <td>0.065121</td>\n",
       "      <td>-0.148254</td>\n",
       "      <td>-0.184977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.098626</td>\n",
       "      <td>-0.181614</td>\n",
       "      <td>-0.068002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.069139</td>\n",
       "      <td>0.028670</td>\n",
       "      <td>0.047261</td>\n",
       "      <td>-0.109063</td>\n",
       "      <td>-0.185458</td>\n",
       "      <td>0.639519</td>\n",
       "      <td>-0.352973</td>\n",
       "      <td>-0.135887</td>\n",
       "      <td>-0.054312</td>\n",
       "      <td>0.161509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034153</td>\n",
       "      <td>-0.140719</td>\n",
       "      <td>0.104816</td>\n",
       "      <td>0.096654</td>\n",
       "      <td>-0.163339</td>\n",
       "      <td>-0.204107</td>\n",
       "      <td>-0.098626</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.202611</td>\n",
       "      <td>-0.072398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.335746</td>\n",
       "      <td>-0.076085</td>\n",
       "      <td>-0.039550</td>\n",
       "      <td>0.049980</td>\n",
       "      <td>-0.356497</td>\n",
       "      <td>-0.321464</td>\n",
       "      <td>0.587471</td>\n",
       "      <td>-0.257858</td>\n",
       "      <td>0.327503</td>\n",
       "      <td>0.042654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041790</td>\n",
       "      <td>0.075013</td>\n",
       "      <td>-0.071819</td>\n",
       "      <td>-0.097313</td>\n",
       "      <td>-0.313380</td>\n",
       "      <td>-0.391308</td>\n",
       "      <td>-0.181614</td>\n",
       "      <td>-0.202611</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.132348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.036142</td>\n",
       "      <td>-0.035789</td>\n",
       "      <td>-0.155727</td>\n",
       "      <td>-0.020764</td>\n",
       "      <td>-0.126442</td>\n",
       "      <td>-0.115498</td>\n",
       "      <td>0.211628</td>\n",
       "      <td>-0.102986</td>\n",
       "      <td>-0.059930</td>\n",
       "      <td>0.138988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034473</td>\n",
       "      <td>-0.014563</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>-0.037785</td>\n",
       "      <td>-0.111046</td>\n",
       "      <td>-0.140179</td>\n",
       "      <td>-0.068002</td>\n",
       "      <td>-0.072398</td>\n",
       "      <td>-0.132348</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   1.000000 -0.094706 -0.103837 -0.246762  0.124148  0.095006 -0.210181   \n",
       "1  -0.094706  1.000000 -0.091723 -0.101397  0.031540  0.047170 -0.070402   \n",
       "2  -0.103837 -0.091723  1.000000 -0.123364  0.097580  0.084204 -0.176511   \n",
       "3  -0.246762 -0.101397 -0.123364  1.000000 -0.143544 -0.112363  0.108507   \n",
       "4   0.124148  0.031540  0.097580 -0.143544  1.000000 -0.288145 -0.621220   \n",
       "5   0.095006  0.047170  0.084204 -0.112363 -0.288145  1.000000 -0.560901   \n",
       "6  -0.210181 -0.070402 -0.176511  0.108507 -0.621220 -0.560901  1.000000   \n",
       "7   0.007803  0.057869  0.086845 -0.136621  0.307655 -0.124442 -0.152124   \n",
       "8   0.067836  0.000701 -0.040976 -0.136907 -0.149344 -0.122618  0.243459   \n",
       "9  -0.079175 -0.057067 -0.077763  0.088725 -0.171537  0.190507 -0.007930   \n",
       "10  0.016567  0.005920  0.005411 -0.097190 -0.097063  0.217142 -0.081501   \n",
       "11 -0.153911 -0.024921  0.064228 -0.062808 -0.049614 -0.060501  0.107827   \n",
       "12  0.121716  0.016302 -0.101414 -0.015729  0.103068 -0.018884 -0.074751   \n",
       "13 -0.054265 -0.003001 -0.051775 -0.318921 -0.016694 -0.018851  0.077981   \n",
       "14  0.031144  0.010618 -0.416147  0.078838 -0.082900  0.009872  0.071362   \n",
       "15  0.134012  0.169757 -0.000541 -0.707618  0.041842  0.007017  0.037656   \n",
       "16 -0.268843 -0.100738  0.049242  0.857738 -0.137774 -0.131846  0.130900   \n",
       "17  0.116998 -0.081106  0.118489 -0.581027  0.110023  0.142598 -0.145158   \n",
       "18  0.014372  0.000815  0.002435 -0.070150  0.176303  0.054700 -0.187849   \n",
       "19  0.081493  0.022539 -0.107925 -0.046340 -0.241679 -0.074078  0.273336   \n",
       "20  0.126311  0.034859  0.105966 -0.129952  0.459163  0.124750 -0.493703   \n",
       "21  0.037751  0.016682  0.034776 -0.055360  0.524565 -0.153057 -0.324302   \n",
       "22  0.069139  0.028670  0.047261 -0.109063 -0.185458  0.639519 -0.352973   \n",
       "23 -0.335746 -0.076085 -0.039550  0.049980 -0.356497 -0.321464  0.587471   \n",
       "24  0.036142 -0.035789 -0.155727 -0.020764 -0.126442 -0.115498  0.211628   \n",
       "\n",
       "          7         8         9     ...           15        16        17  \\\n",
       "0   0.007803  0.067836 -0.079175    ...     0.134012 -0.268843  0.116998   \n",
       "1   0.057869  0.000701 -0.057067    ...     0.169757 -0.100738 -0.081106   \n",
       "2   0.086845 -0.040976 -0.077763    ...    -0.000541  0.049242  0.118489   \n",
       "3  -0.136621 -0.136907  0.088725    ...    -0.707618  0.857738 -0.581027   \n",
       "4   0.307655 -0.149344 -0.171537    ...     0.041842 -0.137774  0.110023   \n",
       "5  -0.124442 -0.122618  0.190507    ...     0.007017 -0.131846  0.142598   \n",
       "6  -0.152124  0.243459 -0.007930    ...     0.037656  0.130900 -0.145158   \n",
       "7   1.000000 -0.138898 -0.781418    ...     0.064391 -0.119726  0.094321   \n",
       "8  -0.138898  1.000000 -0.492727    ...     0.213648 -0.134138 -0.045748   \n",
       "9  -0.781418 -0.492727  1.000000    ...    -0.103434  0.084951  0.018451   \n",
       "10 -0.076486 -0.041959  0.106560    ...     0.035120 -0.116055  0.100936   \n",
       "11 -0.108040  0.179770 -0.000495    ...     0.059676 -0.064140  0.041467   \n",
       "12  0.163624 -0.151685 -0.049990    ...     0.015281  0.006100 -0.011810   \n",
       "13  0.005478  0.026527  0.032310    ...     0.229423 -0.279189  0.204226   \n",
       "14 -0.029355  0.019558  0.022548    ...    -0.044983 -0.340946 -0.035322   \n",
       "15  0.064391  0.213648 -0.103434    ...     1.000000 -0.609172 -0.132901   \n",
       "16 -0.119726 -0.134138  0.084951    ...    -0.609172  1.000000 -0.500687   \n",
       "17  0.094321 -0.045748  0.018451    ...    -0.132901 -0.500687  1.000000   \n",
       "18  0.071444  0.002381 -0.055445    ...    -0.013258 -0.309469 -0.010088   \n",
       "19  0.288894 -0.137222 -0.161972    ...     0.043342 -0.047413  0.026504   \n",
       "20  0.174953 -0.061058 -0.113074    ...     0.044507 -0.108822  0.096022   \n",
       "21 -0.004069 -0.085933  0.060780    ...     0.018460 -0.058603  0.046503   \n",
       "22 -0.135887 -0.054312  0.161509    ...     0.034153 -0.140719  0.104816   \n",
       "23 -0.257858  0.327503  0.042654    ...     0.041790  0.075013 -0.071819   \n",
       "24 -0.102986 -0.059930  0.138988    ...     0.034473 -0.014563  0.002208   \n",
       "\n",
       "          18        19        20        21        22        23        24  \n",
       "0   0.014372  0.081493  0.126311  0.037751  0.069139 -0.335746  0.036142  \n",
       "1   0.000815  0.022539  0.034859  0.016682  0.028670 -0.076085 -0.035789  \n",
       "2   0.002435 -0.107925  0.105966  0.034776  0.047261 -0.039550 -0.155727  \n",
       "3  -0.070150 -0.046340 -0.129952 -0.055360 -0.109063  0.049980 -0.020764  \n",
       "4   0.176303 -0.241679  0.459163  0.524565 -0.185458 -0.356497 -0.126442  \n",
       "5   0.054700 -0.074078  0.124750 -0.153057  0.639519 -0.321464 -0.115498  \n",
       "6  -0.187849  0.273336 -0.493703 -0.324302 -0.352973  0.587471  0.211628  \n",
       "7   0.071444  0.288894  0.174953 -0.004069 -0.135887 -0.257858 -0.102986  \n",
       "8   0.002381 -0.137222 -0.061058 -0.085933 -0.054312  0.327503 -0.059930  \n",
       "9  -0.055445 -0.161972 -0.113074  0.060780  0.161509  0.042654  0.138988  \n",
       "10 -0.028423  0.012926  0.198164 -0.053122 -0.054912 -0.095879 -0.035264  \n",
       "11 -0.004874 -0.185460 -0.297672  0.179096  0.191069  0.345046 -0.188285  \n",
       "12  0.027831  0.180839  0.240122 -0.162093 -0.168888 -0.295760  0.226407  \n",
       "13  0.014780  0.123599 -0.026110 -0.007617  0.001084  0.019750  0.014271  \n",
       "14 -0.037224  0.042721 -0.061319 -0.025924  0.021140  0.028129  0.028611  \n",
       "15 -0.013258  0.043342  0.044507  0.018460  0.034153  0.041790  0.034473  \n",
       "16 -0.309469 -0.047413 -0.108822 -0.058603 -0.140719  0.075013 -0.014563  \n",
       "17 -0.010088  0.026504  0.096022  0.046503  0.104816 -0.071819  0.002208  \n",
       "18  1.000000 -0.053804  0.080382  0.065121  0.096654 -0.097313 -0.037785  \n",
       "19 -0.053804  1.000000 -0.308082 -0.148254 -0.163339 -0.313380 -0.111046  \n",
       "20  0.080382 -0.308082  1.000000 -0.184977 -0.204107 -0.391308 -0.140179  \n",
       "21  0.065121 -0.148254 -0.184977  1.000000 -0.098626 -0.181614 -0.068002  \n",
       "22  0.096654 -0.163339 -0.204107 -0.098626  1.000000 -0.202611 -0.072398  \n",
       "23 -0.097313 -0.313380 -0.391308 -0.181614 -0.202611  1.000000 -0.132348  \n",
       "24 -0.037785 -0.111046 -0.140179 -0.068002 -0.072398 -0.132348  1.000000  \n",
       "\n",
       "[25 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert df to np.array\n",
    "small = small_df.as_matrix()\n",
    "large = large_df.as_matrix()\n",
    "\n",
    "# print small correlation matrix\n",
    "pd.DataFrame(np.corrcoef(small.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course our larger feature set will be much bigger!\n",
    "\n",
    "##### Let's now identify all pairs that fall below our .1 threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uncorrPair(matrix, threshold):\n",
    "\t# return grouped indices\n",
    "\t# for nxn matrix\n",
    "\tresult = []\n",
    "\tm_size = len(matrix)\n",
    "\tfor i in range(m_size):\n",
    "\t\tfor j in range(m_size):\n",
    "\t\t\tif matrix[i][j] < threshold:\n",
    "\t\t\t\tif sorted((j,i)) not in result:\n",
    "\t\t\t\t\tresult.append(list(sorted((i,j))))\n",
    "\treturn list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1], [0, 5], [0, 7], [0, 8], [0, 9], [0, 10], [0, 13], [0, 14], [0, 18], [0, 19]]\n",
      "[[0, 4], [0, 13], [0, 14], [0, 15], [0, 17], [0, 19], [0, 20], [0, 21], [0, 22], [0, 24]]\n"
     ]
    }
   ],
   "source": [
    "# generate list of uncorrelated pairs\n",
    "small_pairs = uncorrPair(np.absolute(np.corrcoef(small.T)), .1)\n",
    "large_pairs = uncorrPair(np.absolute(np.corrcoef(large.T)), .1)\n",
    "print(small_pairs[:10])\n",
    "print(large_pairs[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This is where the fun begins. Let's define a class Network which will mine these pairs for complete networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Network:\n",
    "\tdef __init__(self):\n",
    "\t\t\"\"\"\n",
    "\t\tInitiate class attributes\n",
    "\t\t:attr .network: holds a dictionary of node connections\n",
    "\t\t:attr ._pairs: currently this class ingests a list of list pairs\n",
    "\t\t\t[[0,1], [0,2], ..., [x,y]]\n",
    "\t\t:attr .complete_nodes: list to hold list of nodes that form complete network\n",
    "\t\t\tCurrently, the only purpose of this class is to:\n",
    "\t\t\t\t1. generate node mapping\n",
    "\t\t\t\t2. mine the network graph for all complete subnetworks of any size\n",
    "\t\t\t\t\tMy networks are bidirectional and assume no weights\n",
    "\t\t\"\"\"\n",
    "\t\tself.network = {}\n",
    "\t\tself._pairs = None\n",
    "\t\tself.complete_subnet = []\n",
    "\n",
    "\tdef buildNetwork(self, data):\n",
    "\t\t\"\"\"\n",
    "\t\tCurrently this method takes in list of lists (sublists could be of > 1d)\n",
    "\t\t:param data: list of list holding pair data (could be more)\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\t# store list of list as ._pairs so we can reference in completenessSearch()\n",
    "\t\tself._pairs = data\n",
    "\n",
    "\t\t# store list of unique nodes\n",
    "\t\tnodes = list(set(item for pair in data for item in pair))\n",
    "\n",
    "\t\t# iterate through coordinate data and store node connections in list\n",
    "\t\t# associated with each dictionary node key\n",
    "\t\tfor n in nodes:\n",
    "\t\t\tcon = []\n",
    "\t\t\tfor d in data:\n",
    "\t\t\t\tif n in d:\n",
    "\t\t\t\t\tfor i in d:\n",
    "\t\t\t\t\t\tif i != n:\n",
    "\t\t\t\t\t\t\tcon.append(i)\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t# sort the list and store\n",
    "\t\t\tself.network[n] = list(sorted(con))\n",
    "\n",
    "\tdef completenessSearch(self):\n",
    "\t\t\"\"\"\n",
    "\t\tThe method recursively searches for all\n",
    "\t\tcomplete networks present in self.network\n",
    "\t\t\"\"\"\n",
    "\t\tdef treeSearch(network, shared_match, memory):\n",
    "\t\t\tif shared_match == []:\n",
    "\t\t\t\treturn memory\n",
    "\t\t\telse:\n",
    "\t\t\t\tmemory.append(memory[-1] + [shared_match[0]])\n",
    "\t\t\t\tset_list = [set(network[i]) for i in memory[-1]]\n",
    "\t\t\t\tshared_match = list(set.intersection(*set_list))\n",
    "\t\t\t\treturn treeSearch(network, shared_match, memory)\n",
    "\n",
    "\t\tfor p in self._pairs:\n",
    "\t\t\tstart_match, start_mem = [p[0]], [[p[1]]]\n",
    "\t\t\tself.complete_subnet += treeSearch(self.network, start_match, start_mem)\n",
    "\t\t# remove duplicates\n",
    "\t\tself.complete_subnet = [list(g) for g in set(tuple(g) for g in self.complete_subnet)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's convert our pairwise data to a network mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [1, 5, 7, 8, 9, 10, 13, 14, 18, 19, 21, 22, 24], 1: [0, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24], 2: [1, 4, 5, 7, 8, 9, 10, 11, 13, 15, 16, 18, 21, 22, 23], 3: [9, 10, 11, 12, 14, 18, 19, 21, 23, 24], 4: [1, 2, 10, 11, 13, 14, 15], 5: [0, 1, 2, 11, 12, 13, 14, 15, 18, 19], 6: [1, 9, 10, 12, 13, 14, 15], 7: [0, 1, 2, 10, 13, 14, 15, 17, 18, 21], 8: [0, 1, 2, 10, 13, 14, 17, 18, 20, 21, 22, 24], 9: [0, 1, 2, 3, 6, 11, 12, 13, 14, 16, 17, 18, 21, 23], 10: [0, 1, 2, 3, 4, 6, 7, 8, 12, 13, 14, 15, 18, 19, 21, 22, 23, 24], 11: [1, 2, 3, 4, 5, 9, 13, 14, 15, 16, 17, 18], 12: [1, 3, 5, 6, 9, 10, 13, 14, 15, 16, 17, 18], 13: [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 18, 20, 21, 22, 23, 24], 14: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24], 15: [2, 4, 5, 6, 7, 10, 11, 12, 14, 18, 19, 20, 21, 22, 23, 24], 16: [2, 9, 11, 12, 19, 21, 23, 24], 17: [1, 7, 8, 9, 11, 12, 14, 18, 19, 20, 21, 23, 24], 18: [0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24], 19: [0, 1, 3, 5, 10, 14, 15, 16, 17, 18], 20: [1, 8, 13, 14, 15, 17, 18], 21: [0, 1, 2, 3, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 22, 24], 22: [0, 1, 2, 8, 10, 13, 14, 15, 18, 21, 24], 23: [1, 2, 3, 9, 10, 13, 14, 15, 16, 17, 18], 24: [0, 1, 3, 8, 10, 13, 14, 15, 16, 17, 18, 21, 22]}\n"
     ]
    }
   ],
   "source": [
    "# initiate our networks\n",
    "small_net, large_net = Network(), Network()\n",
    "\n",
    "# map pairwise data\n",
    "small_net.buildNetwork(small_pairs)\n",
    "large_net.buildNetwork(large_pairs)\n",
    "\n",
    "print(small_net.network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the network mapping for our small features. Each key is a node and each list are its pairwise connections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mining complete subnetworks\n",
    "\n",
    "I built a method, completenessSearch() that uses a local recursive function to identify each complete subnetwork in a larger complete subnetwork. Once it cannot expand beyond a subnetwork recursion ends and moves on to the next beginner node. Because we're mining complete networks, all I have to do is keep running set intersections to find the next subnetwork level. \n",
    "\n",
    "You will see that the subnetwork mining has a very low runtime despite the fact that it is not optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.012594223022460938 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# run small search\n",
    "start_time = time.time()\n",
    "small_net.completenessSearch()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10, 1, 0, 7, 18, 13, 21, 14], [16, 9], [14, 6, 1, 9, 12, 13], [19, 10, 0, 1], [18, 8, 0, 1, 10, 13, 24, 21, 14], [21, 8, 0, 1, 10, 13, 24, 18, 14], [12, 5, 1], [13, 10, 0, 1, 7], [5, 2, 1], [18, 3, 9], [23, 15, 18, 2], [9, 1, 0, 18, 13], [24], [22, 14, 0, 1, 8, 10, 24, 18, 21], [14, 8, 0, 1, 10, 13, 24, 18, 21, 22], [10, 1, 0, 7, 18, 13, 21], [9, 0], [13, 9, 0, 1, 18, 21, 14], [24, 17, 1, 8, 18, 21], [7, 0, 1, 10], [22, 2, 1, 8, 21, 10], [10, 7], [18, 8, 0, 1, 10, 13], [19, 10, 0], [24, 14], [14, 1], [9, 0, 1, 18, 13, 21], [22, 14, 0, 1, 8, 10], [15, 4], [11, 5, 1], [21, 7, 0, 1, 10, 18], [23, 9, 1, 2, 18, 13], [13, 8, 0, 1, 10, 14, 24, 18, 21], [22, 10, 0], [12, 5, 1, 18, 13], [18, 12, 1, 5, 13], [14, 5, 0, 1], [23, 1, 2, 9], [21, 1, 0, 7, 10, 18, 13, 14], [13, 12, 1, 5, 18], [24, 3, 10, 18, 21, 14], [17, 8, 1, 14, 24, 18], [14, 13, 0, 1, 5, 18], [14, 10, 0], [24, 22, 0, 1, 8, 10, 18, 13], [7, 2, 1, 21, 10, 18, 13], [22, 21, 0, 1, 8, 10, 24, 18, 13], [20, 14], [18, 10], [18, 17, 1, 7, 21]]\n",
      "Number of uncorrelated feature sets: 930\n"
     ]
    }
   ],
   "source": [
    "# and let's print some of our uncorrelated feature sets\n",
    "print(small_net.complete_subnet[:50])\n",
    "print(\"Number of uncorrelated feature sets: {}\".format(len(small_net.complete_subnet)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.11841607093811035 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# let's see the runtime for the large feature set\n",
    "start_time = time.time()\n",
    "large_net.completenessSearch()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87, 86, 0, 98, 101, 108], [74, 14, 0, 98, 4], [98, 12, 96, 101, 108, 86], [104, 2, 96, 33, 103, 91, 109], [62, 31], [123, 31], [34, 16, 98], [109, 32], [113, 105, 34, 27, 15], [99, 22], [120, 33, 96, 91, 27, 22], [14, 7, 91], [109, 102, 0, 96, 97], [108, 94, 0, 96], [47, 26, 0], [101], [110, 15, 96], [81, 19, 0, 26, 109, 22], [14, 3, 86], [87, 14, 0, 98, 108, 91], [34, 27, 98], [91, 28, 2], [120, 31, 0, 96, 98, 27], [52, 22, 0, 91], [24, 15, 0], [103, 27], [22, 7], [113, 22, 0, 101], [35, 15, 0, 96], [59, 14], [98, 93, 108, 14], [89, 15, 105], [28, 22, 2], [85, 29, 98], [42, 15, 0], [97, 96, 0, 98], [44, 15], [27, 22, 0, 96, 35, 91, 95], [105, 15], [91, 44], [27, 24, 0, 96, 98], [111, 33], [81, 22], [126, 91, 0], [110, 98, 96, 97, 103, 108, 109, 111, 91, 95], [26, 4, 0, 101, 103, 108], [70, 22, 0, 26, 19], [77, 34], [63, 19], [58, 22, 0, 14]]\n",
      "Number of uncorrelated feature sets: 5852\n"
     ]
    }
   ],
   "source": [
    "print(large_net.complete_subnet[:50])\n",
    "print(\"Number of uncorrelated feature sets: {}\".format(len(large_net.complete_subnet)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomly generate 10000, 100000, 1000000 pairs and run network\n",
    "from random import randint\n",
    "ten_pair = [[randint(0,1000), randint(0,1000)] for i in range(0,10000)]\n",
    "hun_pair = [[randint(0,10000), randint(0,10000)] for i in range(0,100000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ten_net = Network()\n",
    "ten_net.buildNetwork(ten_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.21075797080993652 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# time how long it takes for 10,000\n",
    "start_time = time.time()\n",
    "ten_net.completenessSearch()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hun_net = Network()\n",
    "hun_net.buildNetwork(hun_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.789815902709961 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# time how long it takes for 100,000\n",
    "start_time = time.time()\n",
    "hun_net.completenessSearch()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one million\n",
    "mil_pair = [[randint(0,100000), randint(0,100000)] for i in range(0,1000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mil_net = Network()\n",
    "mil_net.buildNetwork(mil_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 20.978532075881958 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "mil_net.completenessSearch()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The network submining approach I run above is a good way to traverse and return all acceptable low correlation feature combinations very quickly. This will aid anyone looking to iterate through a lot of models as they test various stacking strategies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
